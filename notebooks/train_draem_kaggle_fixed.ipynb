{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAEM Training on Kaggle - Stage 2: Defect Localization\n",
    "\n",
    "This notebook trains the DRAEM model for bike defect localization.\n",
    "\n",
    "**No annotation required!** Trains only on intact images.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "### 1. Upload Your Data\n",
    "\n",
    "Upload your data folder to Kaggle with this structure:\n",
    "```\n",
    "/kaggle/input/bike-data/\n",
    "\u2514\u2500\u2500 intact/\n",
    "    \u251c\u2500\u2500 bike001.jpg\n",
    "    \u251c\u2500\u2500 bike002.jpg\n",
    "    \u2514\u2500\u2500 ...\n",
    "```\n",
    "\n",
    "### 2. Run All Cells\n",
    "\n",
    "Just run all cells in order!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q opencv-python\n",
    "!pip install -q scikit-image\n",
    "!pip install -q albumentations\n",
    "\n",
    "print(\"\u2705 Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Adjust these settings\n",
    "# ============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Data paths\n",
    "    'intact_dir': '/kaggle/input/bike-data/intact',  # \u26a0\ufe0f Change this to your data path!\n",
    "    'anomaly_source_path': None,  # Optional: path to texture images (DTD dataset)\n",
    "    \n",
    "    # Training parameters\n",
    "    'epochs': 100,\n",
    "    'batch_size': 8,  # Reduce to 4 if GPU memory issues\n",
    "    'learning_rate': 0.0001,\n",
    "    'image_size': 256,\n",
    "    \n",
    "    # Device\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    \n",
    "    # Data loading\n",
    "    'num_workers': 2,\n",
    "    'pin_memory': True,\n",
    "    \n",
    "    # Perlin noise parameters\n",
    "    'min_perlin_scale': 0,\n",
    "    'max_perlin_scale': 6,\n",
    "    \n",
    "    # Output\n",
    "    'output_dir': '/kaggle/working',\n",
    "    'save_interval': 10,  # Save checkpoint every N epochs\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "print(f\"\\n\u2705 Output directory: {CONFIG['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data exists\n",
    "intact_dir = Path(CONFIG['intact_dir'])\n",
    "\n",
    "if not intact_dir.exists():\n",
    "    print(f\"\u274c ERROR: Data directory not found: {intact_dir}\")\n",
    "    print(\"\\nPlease:\")\n",
    "    print(\"1. Upload your data to Kaggle\")\n",
    "    print(\"2. Update CONFIG['intact_dir'] in the cell above\")\n",
    "    print(\"3. Re-run this cell\")\n",
    "else:\n",
    "    # Count images\n",
    "    image_files = []\n",
    "    for ext in ['*.jpg', '*.png', '*.jpeg']:\n",
    "        image_files.extend(list(intact_dir.glob(f'**/{ext}')))\n",
    "    \n",
    "    print(f\"\u2705 Data directory found: {intact_dir}\")\n",
    "    print(f\"\u2705 Found {len(image_files)} intact images\")\n",
    "    \n",
    "    # Show sample images\n",
    "    if len(image_files) > 0:\n",
    "        fig, axes = plt.subplots(1, min(5, len(image_files)), figsize=(15, 3))\n",
    "        if len(image_files) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, img_path in enumerate(image_files[:5]):\n",
    "            img = Image.open(img_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f'{img_path.name}\\n{img.size}')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\n\u2705 Ready to train!\")\n",
    "    else:\n",
    "        print(\"\\n\u274c No images found! Please check your data directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Perlin Noise Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Perlin Noise for Synthetic Anomaly Generation\n",
    "# ============================================================================\n",
    "\n",
    "def rand_perlin_2d(shape, res, fade=lambda t: 6*t**5 - 15*t**4 + 10*t**3):\n",
    "    \"\"\"Generate 2D Perlin noise\"\"\"\n",
    "    delta = (res[0] / shape[0], res[1] / shape[1])\n",
    "    d = (shape[0] // res[0], shape[1] // res[1])\n",
    "    \n",
    "    grid = np.mgrid[0:res[0]:delta[0], 0:res[1]:delta[1]].transpose(1, 2, 0) % 1\n",
    "    \n",
    "    # Gradients\n",
    "    angles = 2 * np.pi * np.random.rand(res[0] + 1, res[1] + 1)\n",
    "    gradients = np.dstack((np.cos(angles), np.sin(angles)))\n",
    "    \n",
    "    # Get grid coordinates\n",
    "    g00 = gradients[0:-1, 0:-1].repeat(d[0], 0).repeat(d[1], 1)\n",
    "    g10 = gradients[1:, 0:-1].repeat(d[0], 0).repeat(d[1], 1)\n",
    "    g01 = gradients[0:-1, 1:].repeat(d[0], 0).repeat(d[1], 1)\n",
    "    g11 = gradients[1:, 1:].repeat(d[0], 0).repeat(d[1], 1)\n",
    "    \n",
    "    # Ramps\n",
    "    n00 = np.sum(np.dstack((grid[:, :, 0], grid[:, :, 1])) * g00, 2)\n",
    "    n10 = np.sum(np.dstack((grid[:, :, 0] - 1, grid[:, :, 1])) * g10, 2)\n",
    "    n01 = np.sum(np.dstack((grid[:, :, 0], grid[:, :, 1] - 1)) * g01, 2)\n",
    "    n11 = np.sum(np.dstack((grid[:, :, 0] - 1, grid[:, :, 1] - 1)) * g11, 2)\n",
    "    \n",
    "    # Interpolation\n",
    "    t = fade(grid)\n",
    "    n0 = n00 * (1 - t[:, :, 0]) + t[:, :, 0] * n10\n",
    "    n1 = n01 * (1 - t[:, :, 0]) + t[:, :, 0] * n11\n",
    "    \n",
    "    return np.sqrt(2) * ((1 - t[:, :, 1]) * n0 + t[:, :, 1] * n1)\n",
    "\n",
    "\n",
    "def rand_perlin_2d_octaves(shape, res, octaves=1, persistence=0.5):\n",
    "    \"\"\"Generate multi-octave Perlin noise\"\"\"\n",
    "    noise = np.zeros(shape)\n",
    "    frequency = 1\n",
    "    amplitude = 1\n",
    "    \n",
    "    for _ in range(octaves):\n",
    "        noise += amplitude * rand_perlin_2d(\n",
    "            shape,\n",
    "            (frequency * res[0], frequency * res[1])\n",
    "        )\n",
    "        frequency *= 2\n",
    "        amplitude *= persistence\n",
    "    \n",
    "    return noise\n",
    "\n",
    "\n",
    "def generate_perlin_noise_mask(img_size, min_perlin_scale=0, max_perlin_scale=6):\n",
    "    \"\"\"Generate binary anomaly mask using Perlin noise\"\"\"\n",
    "    perlin_scale = 2 ** np.random.randint(min_perlin_scale, max_perlin_scale)\n",
    "    \n",
    "    perlin_noise = rand_perlin_2d_octaves(\n",
    "        img_size,\n",
    "        (perlin_scale, perlin_scale),\n",
    "        octaves=3\n",
    "    )\n",
    "    \n",
    "    threshold = np.random.uniform(0.0, 0.5)\n",
    "    mask = np.where(perlin_noise > threshold, 1.0, 0.0)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def generate_smooth_anomaly(img_size, min_perlin_scale=0, max_perlin_scale=6):\n",
    "    \"\"\"Generate smooth anomaly pattern\"\"\"\n",
    "    perlin_scale = 2 ** np.random.randint(min_perlin_scale, max_perlin_scale)\n",
    "    \n",
    "    perlin_noise = rand_perlin_2d_octaves(\n",
    "        img_size,\n",
    "        (perlin_scale, perlin_scale),\n",
    "        octaves=4,\n",
    "        persistence=0.6\n",
    "    )\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    perlin_noise = (perlin_noise - perlin_noise.min()) / (perlin_noise.max() - perlin_noise.min() + 1e-8)\n",
    "    \n",
    "    return perlin_noise\n",
    "\n",
    "\n",
    "print(\"\u2705 Perlin noise functions defined\")\n",
    "\n",
    "# Test Perlin noise\n",
    "test_noise = rand_perlin_2d_octaves((128, 128), (4, 4), octaves=3)\n",
    "test_mask = generate_perlin_noise_mask((128, 128))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].imshow(test_noise, cmap='gray')\n",
    "axes[0].set_title('Perlin Noise')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(test_mask, cmap='gray')\n",
    "axes[1].set_title('Binary Mask')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2705 Perlin noise working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Anomaly Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Synthetic Anomaly Generator\n",
    "# ============================================================================\n",
    "\n",
    "class AnomalyGenerator:\n",
    "    \"\"\"Generate synthetic anomalies for training\"\"\"\n",
    "    \n",
    "    def __init__(self, anomaly_source_path=None, resize_shape=(256, 256)):\n",
    "        self.resize_shape = resize_shape\n",
    "        self.anomaly_source_path = anomaly_source_path\n",
    "        self.anomaly_source_images = []\n",
    "        \n",
    "        if anomaly_source_path and Path(anomaly_source_path).exists():\n",
    "            self.anomaly_source_images = self._load_anomaly_sources()\n",
    "            print(f\"[OK] Loaded {len(self.anomaly_source_images)} anomaly source images\")\n",
    "        else:\n",
    "            print(\"[INFO] No anomaly source images, using only Perlin noise\")\n",
    "    \n",
    "    def _load_anomaly_sources(self):\n",
    "        source_path = Path(self.anomaly_source_path)\n",
    "        image_files = []\n",
    "        for ext in ['*.jpg', '*.png', '*.jpeg']:\n",
    "            image_files.extend(list(source_path.glob(f'**/{ext}')))\n",
    "        return image_files\n",
    "    \n",
    "    def generate_anomaly(self, img):\n",
    "        \"\"\"Generate synthetic anomaly on normal image\"\"\"\n",
    "        if isinstance(img, Image.Image):\n",
    "            img = np.array(img)\n",
    "        \n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Generate Perlin noise mask\n",
    "        perlin_mask = generate_perlin_noise_mask(\n",
    "            (h, w),\n",
    "            min_perlin_scale=CONFIG['min_perlin_scale'],\n",
    "            max_perlin_scale=CONFIG['max_perlin_scale']\n",
    "        )\n",
    "        \n",
    "        # Augment mask\n",
    "        perlin_mask = self._augment_mask(perlin_mask)\n",
    "        \n",
    "        # Choose anomaly type\n",
    "        if len(self.anomaly_source_images) > 0:\n",
    "            anomaly_type = random.choice(['texture', 'noise', 'brightness'])\n",
    "        else:\n",
    "            anomaly_type = random.choice(['noise', 'brightness'])\n",
    "        \n",
    "        if anomaly_type == 'texture' and len(self.anomaly_source_images) > 0:\n",
    "            augmented_img = self._texture_anomaly(img, perlin_mask)\n",
    "        elif anomaly_type == 'noise':\n",
    "            augmented_img = self._noise_anomaly(img, perlin_mask)\n",
    "        else:\n",
    "            augmented_img = self._brightness_anomaly(img, perlin_mask)\n",
    "        \n",
    "        augmented_img = np.clip(augmented_img, 0, 255).astype(np.uint8)\n",
    "        anomaly_mask = (perlin_mask > 0).astype(np.float32)\n",
    "        \n",
    "        return augmented_img, anomaly_mask\n",
    "    \n",
    "    def _texture_anomaly(self, img, mask):\n",
    "        texture_path = random.choice(self.anomaly_source_images)\n",
    "        texture = Image.open(texture_path).convert('RGB')\n",
    "        texture = texture.resize((img.shape[1], img.shape[0]))\n",
    "        texture = np.array(texture)\n",
    "        \n",
    "        smooth_weight = generate_smooth_anomaly(\n",
    "            (img.shape[0], img.shape[1]),\n",
    "            min_perlin_scale=0,\n",
    "            max_perlin_scale=4\n",
    "        )\n",
    "        \n",
    "        mask_3ch = np.stack([mask] * 3, axis=2)\n",
    "        weight_3ch = np.stack([smooth_weight] * 3, axis=2)\n",
    "        \n",
    "        augmented = img * (1 - mask_3ch) + texture * mask_3ch * weight_3ch + img * mask_3ch * (1 - weight_3ch)\n",
    "        return augmented\n",
    "    \n",
    "    def _noise_anomaly(self, img, mask):\n",
    "        noise = np.random.randint(0, 255, img.shape, dtype=np.uint8)\n",
    "        noise = cv2.GaussianBlur(noise, (5, 5), 0)\n",
    "        \n",
    "        smooth_weight = generate_smooth_anomaly(\n",
    "            (img.shape[0], img.shape[1]),\n",
    "            min_perlin_scale=1,\n",
    "            max_perlin_scale=5\n",
    "        )\n",
    "        \n",
    "        mask_3ch = np.stack([mask] * 3, axis=2)\n",
    "        weight_3ch = np.stack([smooth_weight] * 3, axis=2)\n",
    "        \n",
    "        augmented = img * (1 - mask_3ch * weight_3ch) + noise * mask_3ch * weight_3ch\n",
    "        return augmented\n",
    "    \n",
    "    def _brightness_anomaly(self, img, mask):\n",
    "        brightness_factor = random.uniform(0.3, 2.0)\n",
    "        mask_3ch = np.stack([mask] * 3, axis=2)\n",
    "        \n",
    "        augmented = img.copy().astype(np.float32)\n",
    "        augmented = augmented * (1 - mask_3ch) + augmented * brightness_factor * mask_3ch\n",
    "        return augmented\n",
    "    \n",
    "    def _augment_mask(self, mask):\n",
    "        kernel_size = random.choice([3, 5, 7])\n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        operation = random.choice(['erode', 'dilate', 'open', 'close', 'none'])\n",
    "        \n",
    "        # Ensure mask is numpy array and convert to uint8\n",
    "        mask = np.asarray(mask, dtype=np.float32)\n",
    "        mask_uint8 = (mask * 255).astype(np.uint8)\n",
    "        \n",
    "        if operation == 'erode':\n",
    "            mask = cv2.erode(mask_uint8, kernel, iterations=1) / 255.0\n",
    "        elif operation == 'dilate':\n",
    "            mask = cv2.dilate(mask_uint8, kernel, iterations=1) / 255.0\n",
    "        elif operation == 'open':\n",
    "            mask = cv2.morphologyEx(mask_uint8, cv2.MORPH_OPEN, kernel) / 255.0\n",
    "        elif operation == 'close':\n",
    "            mask = cv2.morphologyEx(mask_uint8, cv2.MORPH_CLOSE, kernel) / 255.0\n",
    "        else:\n",
    "            mask = mask_uint8 / 255.0\n",
    "        \n",
    "        return mask\n",
    "\n",
    "\n",
    "print(\"\u2705 Anomaly generator defined\")\n",
    "\n",
    "# Test anomaly generation\n",
    "test_img = np.random.randint(100, 200, (256, 256, 3), dtype=np.uint8)\n",
    "generator = AnomalyGenerator()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "for i in range(3):\n",
    "    aug_img, mask = generator.generate_anomaly(test_img)\n",
    "    axes[0, i].imshow(aug_img)\n",
    "    axes[0, i].set_title(f'Augmented {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].imshow(mask, cmap='gray')\n",
    "    axes[1, i].set_title(f'Mask {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2705 Anomaly generator working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. DRAEM Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DRAEM Model Architecture\n",
    "# ============================================================================\n",
    "\n",
    "class EncoderReconstructive(nn.Module):\n",
    "    def __init__(self, in_channels, base_width):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, base_width, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width, base_width, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.mp1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(base_width, base_width * 2, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width * 2, base_width * 2, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.mp2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(base_width * 2, base_width * 4, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width * 4, base_width * 4, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 4),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.mp3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(base_width * 4, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width * 8, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.mp4 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.block5 = nn.Sequential(\n",
    "            nn.Conv2d(base_width * 8, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width * 8, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b1 = self.block1(x)\n",
    "        mp1 = self.mp1(b1)\n",
    "        b2 = self.block2(mp1)\n",
    "        mp2 = self.mp2(b2)\n",
    "        b3 = self.block3(mp2)\n",
    "        mp3 = self.mp3(b3)\n",
    "        b4 = self.block4(mp3)\n",
    "        mp4 = self.mp4(b4)\n",
    "        b5 = self.block5(mp4)\n",
    "        return b5\n",
    "\n",
    "\n",
    "class DecoderReconstructive(nn.Module):\n",
    "    def __init__(self, base_width, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(base_width * 8, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(base_width * 8, base_width * 4, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 4),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.up3 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(base_width * 4, base_width * 2, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.up4 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(base_width * 2, base_width, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.final = nn.Conv2d(base_width, out_channels, 1)\n",
    "    \n",
    "    def forward(self, b5):\n",
    "        up1 = self.up1(b5)\n",
    "        up2 = self.up2(up1)\n",
    "        up3 = self.up3(up2)\n",
    "        up4 = self.up4(up3)\n",
    "        output = self.final(up4)\n",
    "        return output\n",
    "\n",
    "\n",
    "class ReconstructiveSubNetwork(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, base_width=128):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderReconstructive(in_channels, base_width)\n",
    "        self.decoder = DecoderReconstructive(base_width, out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b5 = self.encoder(x)\n",
    "        output = self.decoder(b5)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Similar implementation for Discriminative network...\n",
    "# (Code continues in next cell due to length)\n",
    "\n",
    "print(\"\u2705 Reconstructive network defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DRAEM Model - Part 2: Discriminative Network\n",
    "# ============================================================================\n",
    "\n",
    "class EncoderDiscriminative(nn.Module):\n",
    "    def __init__(self, in_channels, base_width):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, base_width, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width, base_width, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.mp1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(base_width, base_width * 2, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width * 2, base_width * 2, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.mp2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(base_width * 2, base_width * 4, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width * 4, base_width * 4, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 4),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.mp3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(base_width * 4, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width * 8, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.mp4 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.block5 = nn.Sequential(\n",
    "            nn.Conv2d(base_width * 8, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width * 8, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.mp5 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.block6 = nn.Sequential(\n",
    "            nn.Conv2d(base_width * 8, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width * 8, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b1 = self.block1(x)\n",
    "        mp1 = self.mp1(b1)\n",
    "        b2 = self.block2(mp1)\n",
    "        mp2 = self.mp2(b2)\n",
    "        b3 = self.block3(mp2)\n",
    "        mp3 = self.mp3(b3)\n",
    "        b4 = self.block4(mp3)\n",
    "        mp4 = self.mp4(b4)\n",
    "        b5 = self.block5(mp4)\n",
    "        mp5 = self.mp5(b5)\n",
    "        b6 = self.block6(mp5)\n",
    "        return b1, b2, b3, b4, b5, b6\n",
    "\n",
    "\n",
    "class DecoderDiscriminative(nn.Module):\n",
    "    def __init__(self, base_width, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(base_width * 8, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.db1 = nn.Sequential(\n",
    "            nn.Conv2d(base_width * 16, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width * 8, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(base_width * 8, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.db2 = nn.Sequential(\n",
    "            nn.Conv2d(base_width * 16, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width * 8, base_width * 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.up3 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(base_width * 8, base_width * 4, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 4),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.db3 = nn.Sequential(\n",
    "            nn.Conv2d(base_width * 8, base_width * 4, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width * 4, base_width * 4, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 4),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.up4 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(base_width * 4, base_width * 2, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.db4 = nn.Sequential(\n",
    "            nn.Conv2d(base_width * 4, base_width * 2, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width * 2, base_width * 2, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width * 2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.up5 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(base_width * 2, base_width, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.db5 = nn.Sequential(\n",
    "            nn.Conv2d(base_width * 2, base_width, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(base_width, base_width, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_width),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.final = nn.Conv2d(base_width, out_channels, 1)\n",
    "    \n",
    "    def forward(self, b1, b2, b3, b4, b5, b6):\n",
    "        up1 = self.up1(b6)\n",
    "        cat1 = torch.cat((up1, b5), dim=1)\n",
    "        db1 = self.db1(cat1)\n",
    "        \n",
    "        up2 = self.up2(db1)\n",
    "        cat2 = torch.cat((up2, b4), dim=1)\n",
    "        db2 = self.db2(cat2)\n",
    "        \n",
    "        up3 = self.up3(db2)\n",
    "        cat3 = torch.cat((up3, b3), dim=1)\n",
    "        db3 = self.db3(cat3)\n",
    "        \n",
    "        up4 = self.up4(db3)\n",
    "        cat4 = torch.cat((up4, b2), dim=1)\n",
    "        db4 = self.db4(cat4)\n",
    "        \n",
    "        up5 = self.up5(db4)\n",
    "        cat5 = torch.cat((up5, b1), dim=1)\n",
    "        db5 = self.db5(cat5)\n",
    "        \n",
    "        output = self.final(db5)\n",
    "        return output\n",
    "\n",
    "\n",
    "class DiscriminativeSubNetwork(nn.Module):\n",
    "    def __init__(self, in_channels=6, out_channels=2, base_width=64):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderDiscriminative(in_channels, base_width)\n",
    "        self.decoder = DecoderDiscriminative(base_width, out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b1, b2, b3, b4, b5, b6 = self.encoder(x)\n",
    "        output = self.decoder(b1, b2, b3, b4, b5, b6)\n",
    "        return output\n",
    "\n",
    "\n",
    "class DRAEM(nn.Module):\n",
    "    \"\"\"Complete DRAEM model\"\"\"\n",
    "    def __init__(self, in_channels=3, out_channels_seg=2):\n",
    "        super().__init__()\n",
    "        self.reconstructive = ReconstructiveSubNetwork(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=in_channels,\n",
    "            base_width=128\n",
    "        )\n",
    "        self.discriminative = DiscriminativeSubNetwork(\n",
    "            in_channels=in_channels * 2,\n",
    "            out_channels=out_channels_seg,\n",
    "            base_width=64\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        reconstruction = self.reconstructive(x)\n",
    "        combined = torch.cat([x, reconstruction], dim=1)\n",
    "        segmentation = self.discriminative(combined)\n",
    "        return reconstruction, segmentation\n",
    "\n",
    "\n",
    "print(\"\u2705 Complete DRAEM model defined\")\n",
    "\n",
    "# Test model\n",
    "test_model = DRAEM()\n",
    "test_input = torch.randn(1, 3, 256, 256)\n",
    "test_recon, test_seg = test_model(test_input)\n",
    "print(f\"  Input: {test_input.shape}\")\n",
    "print(f\"  Reconstruction: {test_recon.shape}\")\n",
    "print(f\"  Segmentation: {test_seg.shape}\")\n",
    "print(\"\u2705 Model architecture working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Dataset\n",
    "# ============================================================================\n",
    "\n",
    "class DRAEMDataset(Dataset):\n",
    "    \"\"\"Dataset for DRAEM training with synthetic anomalies\"\"\"\n",
    "    \n",
    "    def __init__(self, intact_dir, anomaly_source_path=None, transform=None, image_size=256):\n",
    "        self.intact_dir = Path(intact_dir)\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        # Get all intact images\n",
    "        self.image_paths = []\n",
    "        for ext in ['*.jpg', '*.png', '*.jpeg']:\n",
    "            self.image_paths.extend(list(self.intact_dir.glob(f'**/{ext}')))\n",
    "        \n",
    "        print(f\"[OK] Found {len(self.image_paths)} intact images\")\n",
    "        \n",
    "        # Anomaly generator\n",
    "        self.anomaly_generator = AnomalyGenerator(\n",
    "            anomaly_source_path=anomaly_source_path,\n",
    "            resize_shape=(image_size, image_size)\n",
    "        )\n",
    "        \n",
    "        # Transforms\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]\n",
    "                )\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load intact image\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = img.resize((self.image_size, self.image_size))\n",
    "        img_np = np.array(img)\n",
    "        \n",
    "        # Generate synthetic anomaly\n",
    "        aug_img, anomaly_mask = self.anomaly_generator.generate_anomaly(img_np)\n",
    "        \n",
    "        # Convert to PIL for transforms\n",
    "        aug_img_pil = Image.fromarray(aug_img)\n",
    "        \n",
    "        # Apply transforms\n",
    "        intact_tensor = self.transform(img)\n",
    "        augmented_tensor = self.transform(aug_img_pil)\n",
    "        \n",
    "        # Mask to tensor\n",
    "        mask_tensor = torch.from_numpy(anomaly_mask).unsqueeze(0).float()\n",
    "        \n",
    "        return intact_tensor, augmented_tensor, mask_tensor\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = DRAEMDataset(\n",
    "    intact_dir=CONFIG['intact_dir'],\n",
    "    anomaly_source_path=CONFIG['anomaly_source_path'],\n",
    "    image_size=CONFIG['image_size']\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=CONFIG['pin_memory']\n",
    ")\n",
    "\n",
    "print(f\"\u2705 Dataset created: {len(train_dataset)} samples\")\n",
    "print(f\"\u2705 DataLoader created: {len(train_loader)} batches\")\n",
    "\n",
    "# Visualize sample batch\n",
    "intact, augmented, mask = next(iter(train_loader))\n",
    "\n",
    "# Denormalize for visualization\n",
    "def denormalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return tensor * std + mean\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "for i in range(min(4, CONFIG['batch_size'])):\n",
    "    intact_img = denormalize(intact[i]).permute(1, 2, 0).numpy()\n",
    "    augmented_img = denormalize(augmented[i]).permute(1, 2, 0).numpy()\n",
    "    mask_img = mask[i].squeeze().numpy()\n",
    "    \n",
    "    axes[0, i].imshow(np.clip(intact_img, 0, 1))\n",
    "    axes[0, i].set_title('Intact')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(np.clip(augmented_img, 0, 1))\n",
    "    axes[1, i].set_title('Augmented')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    axes[2, i].imshow(mask_img, cmap='gray')\n",
    "    axes[2, i].set_title('Mask')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2705 Data pipeline working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Loss Functions\n",
    "# ============================================================================\n",
    "\n",
    "def ssim(img1, img2, window_size=11):\n",
    "    \"\"\"Structural Similarity Index\"\"\"\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "    \n",
    "    mu1 = F.avg_pool2d(img1, window_size, stride=1, padding=window_size // 2)\n",
    "    mu2 = F.avg_pool2d(img2, window_size, stride=1, padding=window_size // 2)\n",
    "    \n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    \n",
    "    sigma1_sq = F.avg_pool2d(img1 * img1, window_size, stride=1, padding=window_size // 2) - mu1_sq\n",
    "    sigma2_sq = F.avg_pool2d(img2 * img2, window_size, stride=1, padding=window_size // 2) - mu2_sq\n",
    "    sigma12 = F.avg_pool2d(img1 * img2, window_size, stride=1, padding=window_size // 2) - mu1_mu2\n",
    "    \n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "               ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    \n",
    "    return ssim_map.mean()\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for handling class imbalance\"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n",
    "class DRAEMLoss(nn.Module):\n",
    "    \"\"\"Combined loss for DRAEM training\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l2_loss = nn.MSELoss()\n",
    "        self.focal_loss = FocalLoss()\n",
    "    \n",
    "    def forward(self, reconstruction, segmentation, target_img, target_mask):\n",
    "        # Reconstruction loss\n",
    "        recon_loss = self.l2_loss(reconstruction, target_img)\n",
    "        \n",
    "        # SSIM loss\n",
    "        ssim_loss = 1 - ssim(reconstruction, target_img)\n",
    "        \n",
    "        # Segmentation loss\n",
    "        target_mask_long = target_mask.squeeze(1).long()\n",
    "        seg_loss = self.focal_loss(segmentation, target_mask_long)\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = recon_loss + ssim_loss + seg_loss\n",
    "        \n",
    "        return total_loss, recon_loss, ssim_loss, seg_loss\n",
    "\n",
    "\n",
    "print(\"\u2705 Loss functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "# Create model\n",
    "device = torch.device(CONFIG['device'])\n",
    "model = DRAEM().to(device)\n",
    "\n",
    "print(f\"Model on device: {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M\")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = DRAEMLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.reconstructive.parameters(), 'lr': CONFIG['learning_rate']},\n",
    "    {'params': model.discriminative.parameters(), 'lr': CONFIG['learning_rate']}\n",
    "])\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=[\n",
    "        int(CONFIG['epochs'] * 0.8),\n",
    "        int(CONFIG['epochs'] * 0.9)\n",
    "    ],\n",
    "    gamma=0.2\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Epochs: {CONFIG['epochs']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'total_loss': [],\n",
    "    'recon_loss': [],\n",
    "    'ssim_loss': [],\n",
    "    'seg_loss': []\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_recon_loss = 0\n",
    "    epoch_ssim_loss = 0\n",
    "    epoch_seg_loss = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']}\")\n",
    "    \n",
    "    for batch_idx, (intact, augmented, mask) in enumerate(pbar):\n",
    "        intact = intact.to(device)\n",
    "        augmented = augmented.to(device)\n",
    "        mask = mask.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        reconstruction, segmentation = model(augmented)\n",
    "        \n",
    "        # Compute loss\n",
    "        total_loss, recon_loss, ssim_loss, seg_loss = criterion(\n",
    "            reconstruction, segmentation, intact, mask\n",
    "        )\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track losses\n",
    "        epoch_loss += total_loss.item()\n",
    "        epoch_recon_loss += recon_loss.item()\n",
    "        epoch_ssim_loss += ssim_loss.item()\n",
    "        epoch_seg_loss += seg_loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{total_loss.item():.4f}',\n",
    "            'recon': f'{recon_loss.item():.4f}',\n",
    "            'seg': f'{seg_loss.item():.4f}'\n",
    "        })\n",
    "    \n",
    "    # Epoch statistics\n",
    "    n_batches = len(train_loader)\n",
    "    avg_total = epoch_loss / n_batches\n",
    "    avg_recon = epoch_recon_loss / n_batches\n",
    "    avg_ssim = epoch_ssim_loss / n_batches\n",
    "    avg_seg = epoch_seg_loss / n_batches\n",
    "    \n",
    "    history['total_loss'].append(avg_total)\n",
    "    history['recon_loss'].append(avg_recon)\n",
    "    history['ssim_loss'].append(avg_ssim)\n",
    "    history['seg_loss'].append(avg_seg)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    print(f\"  Total Loss: {avg_total:.4f}\")\n",
    "    print(f\"  Reconstruction Loss: {avg_recon:.4f}\")\n",
    "    print(f\"  SSIM Loss: {avg_ssim:.4f}\")\n",
    "    print(f\"  Segmentation Loss: {avg_seg:.4f}\")\n",
    "    print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Step scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if (epoch + 1) % CONFIG['save_interval'] == 0:\n",
    "        checkpoint_path = f\"{CONFIG['output_dir']}/draem_epoch_{epoch+1}.pth\"\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': avg_total,\n",
    "            'config': CONFIG\n",
    "        }, checkpoint_path)\n",
    "        print(f\"  [OK] Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "final_model_path = f\"{CONFIG['output_dir']}/draem_final.pth\"\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'history': history\n",
    "}, final_model_path)\n",
    "\n",
    "print(f\"\u2705 Final model saved: {final_model_path}\")\n",
    "print(f\"\u2705 Model size: {os.path.getsize(final_model_path) / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].plot(history['total_loss'])\n",
    "axes[0, 0].set_title('Total Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "axes[0, 1].plot(history['recon_loss'])\n",
    "axes[0, 1].set_title('Reconstruction Loss')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "axes[1, 0].plot(history['ssim_loss'])\n",
    "axes[1, 0].set_title('SSIM Loss')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "axes[1, 1].plot(history['seg_loss'])\n",
    "axes[1, 1].set_title('Segmentation Loss')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CONFIG['output_dir']}/training_history.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\u2705 Training history saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. Download Model\n",
    "\n",
    "Download the trained model from Kaggle to use locally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all saved files\n",
    "print(\"Saved files:\")\n",
    "for file in Path(CONFIG['output_dir']).glob('*.pth'):\n",
    "    print(f\"  {file.name} ({file.stat().st_size / 1e6:.2f} MB)\")\n",
    "\n",
    "print(\"\\n\u2705 DRAEM training complete!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Download draem_final.pth from Kaggle output\")\n",
    "print(\"2. Use for inference on your local machine\")\n",
    "print(\"3. Integrate with Stage 1 classifier for complete pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Done! \ud83c\udf89\n",
    "\n",
    "Your DRAEM model is trained!\n",
    "\n",
    "**Download `draem_final.pth` and use it for inference.**\n",
    "\n",
    "**No annotation was needed!** \ud83d\ude80"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}